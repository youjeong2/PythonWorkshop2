{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.6\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 만들기위한 라이브러리 추가\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.datasets import make_blobs, make_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 정보를 출력하기 위해 데이터 플로팅\n",
    "def plot_data(pl, X, y):\n",
    "    # y가 0인 애들중에 x좌표 X[y == 0, 0]\n",
    "    # y가 0인 애들중에 y좌표 X[y == 0, 1]\n",
    "    # (400, 2) 2는 x,y에 대한 정보 = 차원정보\n",
    "    pl.plot(X[y == 0, 0], X[y == 0, 1], 'ob', alpha = 0.5)\n",
    "   # y가 1인 애들중에 x좌표 X[y == 1, 0]\n",
    "    # y가 1인 애들중에 y좌표 X[y == 1, 1]\n",
    "    pl.plot(X[y == 1, 0], X[y == 1, 1], 'xr', alpha = 0.5)\n",
    "    pl.legend(['0', '1'])\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0\n",
      " 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0\n",
      " 1 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0\n",
      " 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0\n",
      " 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1\n",
      " 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0\n",
      " 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 1 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# 원 make = x, y 값이 만들어 진다는 것\n",
    "X, y = make_circles(\n",
    "    n_samples = 400, \n",
    "    factor = 0.6, \n",
    "    noise = 0.1, \n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "# y = 0 - 원의 범주에서 벗어나 있음, y = 1 - 원의 범주에 있음\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl = plot_data(plt, X, y)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size = (400, 2)\n",
      "y size = (400,)\n",
      "Num of Samples = 400\n"
     ]
    }
   ],
   "source": [
    "# 랜덤값 주기 위해  seed값 주기 \n",
    "seed = 1\n",
    "\n",
    "print(\"X size =\", X.shape)\n",
    "print(\"y size =\", y.shape)\n",
    "print(\"Num of Samples =\", X.shape[0])\n",
    "# x가 왜 400과 2 일까? \n",
    "# 400 = 샘플개수, 2 = ? \n",
    "# X를 프린트 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.22047667e-01  2.45076964e-01]\n",
      " [-4.90174568e-01  4.04540597e-01]\n",
      " [ 4.69901235e-01  9.04544287e-01]\n",
      " [ 7.37010889e-01  1.11486553e-01]\n",
      " [-9.86636209e-01  1.69521513e-01]\n",
      " [-7.17008501e-01  4.38359514e-01]\n",
      " [-4.41013452e-01 -5.31920699e-01]\n",
      " [-9.95858989e-01  1.08030813e-01]\n",
      " [-3.25897203e-01  5.41504194e-01]\n",
      " [-6.96094447e-01 -6.45797770e-01]\n",
      " [ 9.28358178e-01  2.58529455e-01]\n",
      " [ 2.30348927e-01 -3.40047801e-01]\n",
      " [-2.66141506e-01  1.17464969e+00]\n",
      " [-7.55781307e-01  7.93410286e-01]\n",
      " [-5.69765424e-01 -9.25855019e-01]\n",
      " [ 3.18599125e-01  1.02857282e+00]\n",
      " [-5.10432759e-01  1.73074993e-01]\n",
      " [ 3.95376430e-01 -3.96807852e-01]\n",
      " [ 3.37431388e-01  5.71841873e-01]\n",
      " [ 7.27958177e-01 -2.31006816e-01]\n",
      " [-6.93334233e-01  6.76130038e-01]\n",
      " [ 1.00825010e+00  5.07130501e-01]\n",
      " [ 6.51086779e-01  1.35010193e-02]\n",
      " [-3.45045802e-01  4.46996781e-01]\n",
      " [ 1.04462893e+00  1.13624232e-01]\n",
      " [ 6.45411496e-01  3.08639177e-02]\n",
      " [-9.71724535e-01 -5.12587714e-01]\n",
      " [ 3.69760307e-01  2.97525839e-01]\n",
      " [-2.09844774e-01  5.14863353e-01]\n",
      " [-8.69093566e-01 -2.54455670e-01]\n",
      " [ 7.48105272e-01 -1.91980713e-01]\n",
      " [ 8.52093677e-01 -3.00608374e-01]\n",
      " [-8.11474357e-03  5.60519948e-01]\n",
      " [-1.65199690e-01  9.57527588e-01]\n",
      " [ 3.12488214e-01  4.56008750e-01]\n",
      " [-8.71232284e-01 -4.32293685e-01]\n",
      " [-7.49924075e-01 -5.84594778e-01]\n",
      " [ 1.18680986e-02 -5.28353854e-01]\n",
      " [ 2.11913609e-01 -1.02335551e+00]\n",
      " [-1.74623542e-01 -9.37395832e-01]\n",
      " [ 3.42841833e-01 -3.00943066e-01]\n",
      " [-4.19973115e-02  1.07347481e+00]\n",
      " [-7.91654414e-01  5.50346376e-01]\n",
      " [ 6.74509467e-01  1.03250529e+00]\n",
      " [-9.98827820e-01  4.51553285e-01]\n",
      " [ 5.45800944e-01 -3.33948602e-01]\n",
      " [-8.28110091e-02 -7.95554629e-01]\n",
      " [ 7.41754580e-01 -5.63511433e-01]\n",
      " [ 7.90703987e-01  5.56950321e-01]\n",
      " [ 5.17246591e-01 -7.23179304e-01]\n",
      " [ 3.06699891e-01  1.03257299e+00]\n",
      " [-4.65085749e-01 -3.59471189e-01]\n",
      " [-2.46716505e-01 -4.39517660e-01]\n",
      " [-6.38329480e-01  6.73338446e-01]\n",
      " [ 2.52562871e-01 -4.29480275e-01]\n",
      " [ 4.44807167e-01  9.64629294e-01]\n",
      " [ 4.18329763e-01  4.42631249e-01]\n",
      " [ 6.56045224e-01 -6.87894195e-01]\n",
      " [ 7.20435641e-01  7.13577982e-01]\n",
      " [-1.71169137e-01 -1.03318041e+00]\n",
      " [-8.30902774e-01 -6.01351287e-01]\n",
      " [-6.61805730e-01 -7.51490751e-02]\n",
      " [-1.51280824e-01  4.43415572e-01]\n",
      " [-6.11497471e-01  6.84588185e-01]\n",
      " [-9.34750749e-01  2.21918944e-02]\n",
      " [ 6.46100494e-01  9.40414777e-01]\n",
      " [-1.63002242e-02 -7.40812200e-01]\n",
      " [-4.06189451e-01  5.02071793e-01]\n",
      " [ 3.32938152e-01  1.84379958e-03]\n",
      " [-8.50986587e-01  8.10020402e-01]\n",
      " [-5.02217276e-01 -3.24153619e-01]\n",
      " [-3.56208969e-01 -9.29335869e-01]\n",
      " [ 9.40500588e-01  1.00816350e-01]\n",
      " [ 6.67108319e-02  1.14027134e+00]\n",
      " [ 5.94556833e-01 -1.99925045e-01]\n",
      " [-1.23562387e-02  5.71783987e-01]\n",
      " [ 2.98064198e-01  4.00950289e-01]\n",
      " [ 2.16337788e-01 -3.37333931e-01]\n",
      " [ 6.53278018e-01 -7.72054988e-01]\n",
      " [-6.97089489e-01  1.26122206e-01]\n",
      " [ 9.46072622e-01  8.91603580e-02]\n",
      " [ 7.79795705e-01  3.75765694e-01]\n",
      " [ 4.47358553e-01  1.05640279e-01]\n",
      " [-1.22788749e-02  6.64889324e-01]\n",
      " [-3.32700747e-01  4.52489173e-01]\n",
      " [-5.20320967e-01  9.36713118e-01]\n",
      " [ 1.77633977e-01  5.54073235e-01]\n",
      " [-5.65642411e-01 -2.02242510e-02]\n",
      " [-8.31345381e-01 -3.16468496e-01]\n",
      " [-8.35703329e-01  2.71515932e-01]\n",
      " [ 2.36010254e-01  5.27431224e-01]\n",
      " [-2.38148608e-01 -3.43450954e-01]\n",
      " [-8.12374168e-01 -5.16498989e-01]\n",
      " [ 6.45024491e-01  4.12776546e-01]\n",
      " [ 7.44589476e-01 -4.52188214e-01]\n",
      " [-6.16858108e-01 -3.20392303e-01]\n",
      " [ 3.11935049e-01 -5.43691145e-01]\n",
      " [ 5.18727526e-01 -3.78461368e-01]\n",
      " [-1.44574169e-01  5.37702155e-01]\n",
      " [-7.58898007e-01  7.96389318e-01]\n",
      " [ 1.39126845e-04  8.51262958e-01]\n",
      " [-8.11377158e-01 -3.48008033e-01]\n",
      " [ 9.91268988e-01  5.34274845e-01]\n",
      " [-4.58407094e-01  9.56571906e-01]\n",
      " [ 9.95154007e-02 -9.71526849e-01]\n",
      " [ 1.05825201e+00  4.23388516e-01]\n",
      " [ 8.52200071e-01  5.16703711e-01]\n",
      " [-6.00070976e-01 -7.21624278e-01]\n",
      " [ 6.75365078e-02 -5.39132075e-01]\n",
      " [ 1.71744268e-01 -5.76943704e-01]\n",
      " [-5.81550404e-01 -6.85113277e-01]\n",
      " [ 5.96726482e-01 -1.79678174e-01]\n",
      " [-7.33465984e-01  2.69805453e-01]\n",
      " [ 5.80455038e-01 -3.92626513e-01]\n",
      " [-5.48827768e-01 -1.49787579e-01]\n",
      " [-7.48194741e-02  8.40871036e-01]\n",
      " [-6.28975736e-01  5.31611499e-01]\n",
      " [-4.78581343e-01  1.81181474e-01]\n",
      " [-4.92901482e-01 -1.17392553e-01]\n",
      " [-4.49470390e-01  3.38756465e-01]\n",
      " [ 8.15767627e-02 -9.25506076e-01]\n",
      " [-1.01061743e+00 -1.74459827e-01]\n",
      " [ 8.37156046e-01  5.01365025e-01]\n",
      " [ 1.11827658e-01 -3.59173499e-01]\n",
      " [ 8.07572023e-01  6.55833096e-01]\n",
      " [ 6.69640648e-01 -7.88974480e-01]\n",
      " [-4.36773629e-02 -6.27064911e-01]\n",
      " [-1.25070780e-01 -5.26318922e-01]\n",
      " [ 3.86436115e-01 -8.56575500e-01]\n",
      " [ 1.11673522e-01  5.96176550e-01]\n",
      " [-4.84559339e-01 -1.96342201e-01]\n",
      " [-7.95617158e-02 -1.06572268e+00]\n",
      " [ 2.88590115e-02  6.06397876e-01]\n",
      " [ 7.90132967e-01 -7.39763055e-01]\n",
      " [-7.79897875e-01 -4.96976872e-01]\n",
      " [ 8.65310407e-01 -3.53290473e-01]\n",
      " [ 3.97110835e-01  4.25216025e-01]\n",
      " [-2.46402153e-01  4.05500307e-01]\n",
      " [ 3.50546164e-01  3.42165023e-01]\n",
      " [-6.20528433e-01 -3.41955897e-01]\n",
      " [ 5.60089173e-01  7.74061346e-01]\n",
      " [-8.14054250e-02 -1.00328244e+00]\n",
      " [-5.36020155e-01  3.32089565e-01]\n",
      " [ 3.04377858e-01 -7.89074700e-01]\n",
      " [ 8.39807077e-01 -2.38919783e-01]\n",
      " [-5.03184281e-01  3.73026948e-01]\n",
      " [-2.80113850e-01  7.96494282e-01]\n",
      " [-8.91222953e-01 -3.58163059e-01]\n",
      " [ 4.33366604e-01 -1.11880157e+00]\n",
      " [ 3.18037155e-01 -5.36132369e-01]\n",
      " [ 1.16180371e+00  1.79930550e-01]\n",
      " [-2.48790836e-01 -4.33263399e-01]\n",
      " [-5.98880225e-01  6.85934063e-01]\n",
      " [-4.30792388e-02 -9.50543340e-01]\n",
      " [ 1.01511472e+00  2.27538582e-01]\n",
      " [ 1.15328119e+00 -2.22094360e-01]\n",
      " [-1.01690923e+00 -8.02575171e-02]\n",
      " [-7.50655354e-01  5.63163194e-01]\n",
      " [-4.37591017e-01 -4.57539418e-01]\n",
      " [ 5.24019038e-01 -2.51554343e-01]\n",
      " [ 6.23964884e-01 -2.25864856e-01]\n",
      " [ 6.43811503e-01  4.79521252e-02]\n",
      " [-3.03908404e-01  1.95026127e-01]\n",
      " [ 5.14506082e-01 -8.28374585e-01]\n",
      " [ 1.01616582e-01 -5.32956919e-01]\n",
      " [-8.72484605e-01  3.24285512e-01]\n",
      " [ 5.16876737e-01 -4.15707885e-01]\n",
      " [ 4.55078234e-01 -8.68025448e-01]\n",
      " [-1.78235842e-02 -9.31765295e-01]\n",
      " [ 3.38211156e-01  5.08178963e-01]\n",
      " [-9.03243187e-01  1.19577448e-01]\n",
      " [-5.89487814e-01  8.87891963e-01]\n",
      " [-5.79181820e-01 -5.78821847e-01]\n",
      " [-8.14876903e-01  8.54958945e-02]\n",
      " [-1.93124192e-01 -8.95343232e-01]\n",
      " [-6.43363435e-01 -2.86300855e-01]\n",
      " [-1.18165295e+00  1.93802320e-01]\n",
      " [ 2.89557911e-01  3.23906591e-01]\n",
      " [-7.64732921e-01  9.87576117e-01]\n",
      " [ 8.71583276e-01  5.73225501e-01]\n",
      " [ 3.08960001e-01  9.69015123e-01]\n",
      " [-1.88655730e-01 -8.76847729e-01]\n",
      " [-7.22555150e-01 -4.79120910e-01]\n",
      " [ 9.41335703e-01 -4.63749490e-01]\n",
      " [-5.44253888e-01  8.18209904e-01]\n",
      " [ 9.92850830e-01  1.21303787e-01]\n",
      " [-4.78008649e-01 -3.84675365e-01]\n",
      " [ 2.71768054e-01  4.04830900e-01]\n",
      " [-2.90725388e-01 -3.98788660e-01]\n",
      " [ 1.30513255e+00 -1.38210405e-01]\n",
      " [-9.64399905e-01 -7.45660605e-01]\n",
      " [ 7.71062276e-03 -7.92182981e-01]\n",
      " [ 4.39554087e-01 -3.17333565e-01]\n",
      " [-1.02260561e+00  3.57753133e-01]\n",
      " [-4.23413503e-01 -6.03402539e-01]\n",
      " [-1.09218298e-01 -5.49368334e-01]\n",
      " [-1.51503831e-01 -6.44304177e-01]\n",
      " [-1.23525625e-02 -5.74807800e-01]\n",
      " [-3.49316985e-01 -3.95599091e-01]\n",
      " [-6.61557925e-01 -8.72132360e-02]\n",
      " [ 9.02625968e-01 -5.47970235e-01]\n",
      " [ 4.73842739e-01 -5.34705945e-02]\n",
      " [-4.62668620e-01  1.69553698e-01]\n",
      " [ 7.04244904e-01  1.34202824e-01]\n",
      " [-4.44975174e-01  2.58454815e-01]\n",
      " [-7.04431192e-01 -7.65544644e-01]\n",
      " [ 4.73302899e-01  9.05039711e-01]\n",
      " [ 9.34333034e-01  4.19479656e-01]\n",
      " [-3.40211344e-01 -4.28113241e-01]\n",
      " [ 8.46658535e-01 -4.45724904e-01]\n",
      " [ 4.43216797e-01  4.13751809e-01]\n",
      " [-1.04920353e+00 -3.40406395e-01]\n",
      " [ 7.18324671e-01 -5.22318293e-01]\n",
      " [-4.64033904e-01 -5.15577618e-01]\n",
      " [-5.55164054e-01  2.02676443e-02]\n",
      " [-6.33076864e-01 -6.71971677e-01]\n",
      " [ 3.32481372e-01 -3.93631807e-01]\n",
      " [-5.07898034e-01  3.05731335e-01]\n",
      " [ 4.38697543e-01 -4.50248322e-01]\n",
      " [-4.15682313e-01  2.05327000e-01]\n",
      " [ 1.76072018e-01 -7.70275699e-01]\n",
      " [ 2.82408434e-01 -7.58288077e-01]\n",
      " [-2.61544214e-02  7.13987262e-01]\n",
      " [-3.21780048e-01 -1.00488908e+00]\n",
      " [ 3.68318006e-01 -7.97141442e-01]\n",
      " [ 9.43129916e-01 -3.88231289e-01]\n",
      " [ 9.59908756e-01 -7.02786871e-02]\n",
      " [ 5.24377993e-01 -1.71366142e-01]\n",
      " [ 9.15160925e-01  1.54953991e-01]\n",
      " [ 6.01632145e-01  1.70351346e-01]\n",
      " [-7.68786190e-01 -6.71422856e-01]\n",
      " [ 2.11999983e-01  4.63381079e-01]\n",
      " [ 4.95425970e-01  5.65553312e-01]\n",
      " [ 7.65803166e-01  5.40899450e-01]\n",
      " [-7.94695449e-01 -4.89955954e-01]\n",
      " [ 2.17082453e-01 -5.23210113e-01]\n",
      " [ 4.38681227e-01  4.16885126e-01]\n",
      " [ 1.60835792e-02 -6.60687198e-01]\n",
      " [ 4.85402341e-01 -4.54051975e-01]\n",
      " [ 6.88838247e-02 -5.53321745e-01]\n",
      " [ 6.10830033e-01 -2.71918850e-01]\n",
      " [-6.38585724e-01 -6.75313026e-01]\n",
      " [-5.84036890e-01  6.78224899e-01]\n",
      " [-4.95241045e-01 -3.92136998e-01]\n",
      " [ 5.65353999e-01  8.91723707e-01]\n",
      " [-9.23473081e-01  6.34206563e-01]\n",
      " [ 5.27831141e-01 -1.56003088e-01]\n",
      " [-9.59275247e-01 -3.15741222e-01]\n",
      " [ 1.68574825e-02  6.33068289e-01]\n",
      " [-6.01698089e-01 -5.90707157e-02]\n",
      " [-3.38898491e-01 -8.51972079e-01]\n",
      " [ 3.29985312e-02  7.51449153e-01]\n",
      " [ 9.38045661e-01 -6.01770674e-01]\n",
      " [-6.75083384e-01  1.63170725e-01]\n",
      " [ 2.17112012e-01  1.04456723e+00]\n",
      " [ 4.00442697e-01 -4.62487976e-01]\n",
      " [-3.19315902e-01  9.03685840e-01]\n",
      " [-9.66970462e-01  4.53655413e-01]\n",
      " [ 1.42315866e-01  3.23328354e-01]\n",
      " [ 8.48690367e-01 -3.94358918e-01]\n",
      " [ 2.36569550e-01 -1.02491462e+00]\n",
      " [ 1.02091411e+00  2.76469970e-01]\n",
      " [ 5.25152765e-01  7.57732077e-01]\n",
      " [ 9.13500183e-01  7.48944690e-01]\n",
      " [ 5.55458723e-01 -6.94710404e-01]\n",
      " [-2.90560371e-01 -8.23090380e-01]\n",
      " [-4.69437372e-01 -3.33335867e-01]\n",
      " [-4.04954984e-01  5.83067163e-01]\n",
      " [ 4.97141729e-01  4.10975105e-01]\n",
      " [-9.33588153e-01  1.69728084e-01]\n",
      " [ 2.05764636e-02  9.87674218e-01]\n",
      " [ 1.80429333e-01  4.58722417e-01]\n",
      " [-5.69040012e-01 -1.34279789e-01]\n",
      " [-5.66913014e-01 -1.03261542e-01]\n",
      " [ 8.07971754e-01 -7.42306823e-01]\n",
      " [ 6.70553692e-02  9.25207155e-01]\n",
      " [-6.75225177e-01 -3.63465865e-01]\n",
      " [ 6.66170677e-01  2.72552611e-01]\n",
      " [-1.54895084e-01  5.87691738e-01]\n",
      " [-3.68028588e-01 -5.62138187e-01]\n",
      " [ 1.05848842e+00  2.26347380e-01]\n",
      " [-1.99289508e-01  5.93849037e-01]\n",
      " [ 2.77667236e-01 -5.12246276e-01]\n",
      " [-9.16230256e-01  1.36798531e-01]\n",
      " [ 5.46212781e-01  5.40245439e-01]\n",
      " [-1.52900922e-01 -6.14424513e-01]\n",
      " [ 5.61000552e-01  1.84848066e-01]\n",
      " [ 4.17658366e-01 -8.18104919e-01]\n",
      " [-9.62274104e-01  4.06357775e-03]\n",
      " [ 5.15325936e-01  2.56990628e-01]\n",
      " [-2.03052243e-01  9.04937042e-01]\n",
      " [ 2.29771652e-01  7.24312915e-01]\n",
      " [ 6.70612373e-01  9.74068537e-01]\n",
      " [-2.15199382e-01  3.15253416e-01]\n",
      " [ 7.01888700e-01 -5.01191757e-03]\n",
      " [-1.40504955e-01 -4.59554580e-01]\n",
      " [ 8.05729173e-01  5.59659862e-01]\n",
      " [-5.40323784e-01 -8.20156195e-02]\n",
      " [ 4.75687283e-01  5.69016302e-01]\n",
      " [-4.50135485e-01  6.43588186e-01]\n",
      " [-5.79676281e-01  3.20460484e-01]\n",
      " [ 3.93740699e-01 -9.31764647e-01]\n",
      " [ 4.16761536e-01 -5.02601534e-01]\n",
      " [-3.70552281e-01 -9.85298886e-01]\n",
      " [-5.28665452e-01  9.86561833e-01]\n",
      " [-5.34593532e-01 -9.11085711e-01]\n",
      " [-6.08726594e-01 -9.79035007e-01]\n",
      " [ 7.82448271e-01  2.18716030e-01]\n",
      " [-3.80322943e-01  9.79230880e-01]\n",
      " [-7.59131450e-01  6.36631484e-02]\n",
      " [ 8.80320091e-01  3.37463567e-01]\n",
      " [ 1.22526129e-01 -9.02101518e-01]\n",
      " [ 3.36417573e-01  9.56087169e-01]\n",
      " [ 3.13401778e-01 -4.32974230e-01]\n",
      " [-4.59776599e-01 -3.91355231e-01]\n",
      " [ 6.39601082e-01  2.55893542e-01]\n",
      " [-4.12278948e-01  3.17373784e-01]\n",
      " [-1.16786674e-01 -6.05673796e-01]\n",
      " [ 3.06994860e-01  6.62314428e-01]\n",
      " [ 5.95204584e-01 -1.90977463e-02]\n",
      " [ 6.21010521e-01  4.66258949e-01]\n",
      " [-5.81746121e-01 -7.70160849e-02]\n",
      " [ 2.72432864e-01 -5.43197492e-01]\n",
      " [-2.75573398e-02  6.94244926e-01]\n",
      " [ 7.08461388e-01 -1.17051622e-01]\n",
      " [ 2.59088491e-01 -4.22036036e-01]\n",
      " [-7.46720143e-01 -1.28070600e-01]\n",
      " [-3.97712805e-01  4.93153280e-01]\n",
      " [ 6.50377402e-01 -1.22483939e-03]\n",
      " [ 2.48134341e-01 -8.43395740e-01]\n",
      " [ 1.94597569e-01  9.86129654e-01]\n",
      " [ 5.71551991e-01  3.09312610e-01]\n",
      " [ 9.55383686e-01 -2.05969652e-01]\n",
      " [-5.61039264e-01 -8.11149650e-02]\n",
      " [-1.12927919e-01  7.77864966e-01]\n",
      " [-9.46746999e-01 -9.26371380e-02]\n",
      " [ 1.60573581e-02  1.00192374e+00]\n",
      " [ 9.35721251e-01 -1.60037990e-02]\n",
      " [-1.50399335e-02  9.04473464e-01]\n",
      " [-7.77236477e-01  5.24833597e-01]\n",
      " [ 6.12098286e-01  7.79932347e-02]\n",
      " [ 4.77591525e-01  9.31912345e-01]\n",
      " [-2.92478647e-01  6.14541880e-01]\n",
      " [-8.03562899e-01  3.13302014e-01]\n",
      " [-2.81452321e-01 -6.26030263e-01]\n",
      " [-8.76168096e-02  9.38537699e-01]\n",
      " [-1.92978710e-01 -5.77172277e-01]\n",
      " [-2.77587308e-01  5.61868320e-01]\n",
      " [ 2.86033405e-01  5.52540928e-01]\n",
      " [ 7.99212625e-01  3.57258641e-01]\n",
      " [-4.57561393e-01 -2.04717273e-01]\n",
      " [-8.77912521e-01  3.05653880e-01]\n",
      " [-3.21596857e-01  5.47756550e-01]\n",
      " [ 4.12211511e-01 -8.80463690e-01]\n",
      " [-1.80414197e-01 -5.36295373e-01]\n",
      " [ 4.15041390e-01  7.40449861e-03]\n",
      " [-3.68093197e-01 -9.22003412e-01]\n",
      " [-6.00671529e-01 -2.34922294e-01]\n",
      " [ 5.25340443e-01 -1.88833478e-01]\n",
      " [-5.50508829e-01 -2.49539829e-01]\n",
      " [ 1.77258331e-01  6.43331746e-01]\n",
      " [-1.73764152e-01  9.56652283e-01]\n",
      " [-1.84677243e-01  9.43333059e-01]\n",
      " [ 8.00895652e-01 -8.21901847e-01]\n",
      " [ 8.62850604e-01 -2.74718938e-01]\n",
      " [ 6.37614008e-01  1.25213370e-02]\n",
      " [ 8.01432572e-01 -1.40742096e-01]\n",
      " [ 4.40508040e-01 -8.11655843e-01]\n",
      " [-2.64555437e-01  8.49919009e-01]\n",
      " [ 2.57695772e-02  1.00035749e+00]\n",
      " [-1.77426110e-01 -4.95649988e-01]\n",
      " [ 2.56231725e-01  4.00476447e-01]\n",
      " [-1.80286865e-01  6.59432546e-01]\n",
      " [ 6.41477934e-01  6.44549661e-01]\n",
      " [-5.06187257e-01 -3.37824271e-01]\n",
      " [ 3.98090803e-01 -1.12283588e+00]\n",
      " [-4.07735283e-01  4.06642470e-01]\n",
      " [ 9.48393888e-01 -3.96780770e-01]\n",
      " [-6.79252258e-01  2.92766147e-01]\n",
      " [-9.37044395e-03 -5.11341598e-01]\n",
      " [-3.69011345e-02  6.70151412e-01]\n",
      " [-6.13485518e-01 -1.44453577e-01]\n",
      " [-1.78661597e-01 -1.00847612e+00]\n",
      " [-4.69443827e-01 -8.75087719e-01]\n",
      " [ 1.33724880e-01 -9.90347986e-01]\n",
      " [ 2.88574771e-02 -6.86908163e-01]\n",
      " [-9.07576273e-01  8.66631676e-02]\n",
      " [ 3.92630801e-01 -4.89711127e-01]\n",
      " [-8.96697828e-01  4.85177516e-01]\n",
      " [-2.05085823e-01 -3.33041777e-01]\n",
      " [ 5.80092222e-01  2.38274406e-01]\n",
      " [-7.75530212e-01 -5.60695018e-01]\n",
      " [ 6.51510631e-01  1.11952208e-01]\n",
      " [ 1.02059257e+00  5.67259789e-01]\n",
      " [ 1.14536498e+00 -2.50900628e-01]\n",
      " [-6.22989353e-01  9.40011496e-01]\n",
      " [-8.13722421e-01 -2.33410859e-01]\n",
      " [-1.79449626e-01  5.92918479e-01]\n",
      " [ 1.99181601e-01 -6.41219895e-01]\n",
      " [-1.03336940e+00 -2.65456733e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "# 데이터 400개가 있고 원을 그리기 위한 \n",
    "# 이차원 정보 ->(x, y)의 좌표 정보라는 것을 알려줌\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 데이터에 대한 뉴럴 네트워크만들기 , 원 추적할 수 있도록 \n",
    "# nineth에서 뉴럴네트워크 만들었던거 복붙\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation = 'sigmoid', input_dim = 2))\n",
    "model.compile(optimizer = 'sgd', loss = 'binary_crossentropy')\n",
    "# 이 모델은 망했음 그래프가 노답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 0s 605us/step - loss: 0.7386\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 516us/step - loss: 0.7332\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 516us/step - loss: 0.7282\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 500us/step - loss: 0.7240\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 485us/step - loss: 0.7203\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 461us/step - loss: 0.7169\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 515us/step - loss: 0.7140\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 552us/step - loss: 0.7115\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 498us/step - loss: 0.7091\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 560us/step - loss: 0.7072\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 573us/step - loss: 0.7054\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 643us/step - loss: 0.7039\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 730us/step - loss: 0.7026\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 829us/step - loss: 0.7014\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 732us/step - loss: 0.7004\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 522us/step - loss: 0.6996\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 527us/step - loss: 0.6987\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 489us/step - loss: 0.6982\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 497us/step - loss: 0.6975\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 467us/step - loss: 0.6970\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 474us/step - loss: 0.6965\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 442us/step - loss: 0.6961\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 467us/step - loss: 0.6958\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 474us/step - loss: 0.6955\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 486us/step - loss: 0.6953\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 465us/step - loss: 0.6950\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 469us/step - loss: 0.6948\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 426us/step - loss: 0.6947\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 474us/step - loss: 0.6945\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 457us/step - loss: 0.6944\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 496us/step - loss: 0.6943\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 491us/step - loss: 0.6942\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 515us/step - loss: 0.6941\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 456us/step - loss: 0.6940\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 433us/step - loss: 0.6939\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 485us/step - loss: 0.6939\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 487us/step - loss: 0.6940\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 503us/step - loss: 0.6938\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 480us/step - loss: 0.6937\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 465us/step - loss: 0.6937\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 456us/step - loss: 0.6937\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 473us/step - loss: 0.6937\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 478us/step - loss: 0.6937\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.6936\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 470us/step - loss: 0.6937\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 452us/step - loss: 0.6936\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 462us/step - loss: 0.6937\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 456us/step - loss: 0.6936\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 467us/step - loss: 0.6936\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 467us/step - loss: 0.6935\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 447us/step - loss: 0.6935\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 462us/step - loss: 0.6935\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 491us/step - loss: 0.6935\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 467us/step - loss: 0.6935\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 482us/step - loss: 0.6936\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 467us/step - loss: 0.6936\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 460us/step - loss: 0.6936\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 508us/step - loss: 0.6935\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 553us/step - loss: 0.6935\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 640us/step - loss: 0.6935\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 816us/step - loss: 0.6935\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6935\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6935\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6936\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6935\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 999us/step - loss: 0.6935\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6935\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 706us/step - loss: 0.6935\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 498us/step - loss: 0.6936\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 502us/step - loss: 0.6935\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 598us/step - loss: 0.6936\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 854us/step - loss: 0.6935\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6936\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6936\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 682us/step - loss: 0.6935\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 464us/step - loss: 0.6935\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 474us/step - loss: 0.6936\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 452us/step - loss: 0.6935\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 427us/step - loss: 0.6935\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 488us/step - loss: 0.6935\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 467us/step - loss: 0.6936\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 440us/step - loss: 0.6935\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 410us/step - loss: 0.6935\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 462us/step - loss: 0.6935\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 464us/step - loss: 0.6936\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 469us/step - loss: 0.6935\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 476us/step - loss: 0.6936\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 466us/step - loss: 0.6935\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 457us/step - loss: 0.6935\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 466us/step - loss: 0.6935\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 470us/step - loss: 0.6935\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 697us/step - loss: 0.6935\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 919us/step - loss: 0.6935\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6935\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6936\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6935\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6936\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6935\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 492us/step - loss: 0.6935\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/80 [..............................] - ETA: 0s - loss: 0.6889\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "80/80 [==============================] - 0s 451us/step - loss: 0.6936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fed90574410>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컴파일 잘 되었으면 피팅해주기\n",
    "model.fit(X, y, batch_size = 5, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원 그리기 및 사이즈 조절 \n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(np.meshgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거짓인지 참인지 판정해주는 것을 그려야함\n",
    "# 대각선 개수 늘리고 줄임 min, max\n",
    "def plot_decision_bound(model, X, y):\n",
    "    # X shape -> (400, 2)\n",
    "    # a = x, b = y\n",
    "    # 원의 방정식\n",
    "    amin, bmin = X.min(axis = 0) - 0.1\n",
    "    amax, bmax = X.max(axis = 0) + 0.1\n",
    "    # 대각선이 시작되는 값 알려줌\n",
    "    # 기울기 쳐서 해당영역에 있는 애들이 누군지 알려줌\n",
    "    # print(\"amin =\", amin)\n",
    "    # print(\"bmin =\", bmin)\n",
    "    # print(\"amax =\", amax)\n",
    "    # print(\"bmax =\", bmax)\n",
    "    \n",
    "    # np.linspace()는 \n",
    "    #(첫번째 인자=min)-두번째 인자(=max) 사이의 값을 \n",
    "    # 세번째 인자의 개수만큼(101개) 균일하게 쪼갠다\n",
    "    hticks = np.linspace(amin, amax, 101)\n",
    "    vticks = np.linspace(bmin, bmax, 101)\n",
    "    #print(hticks) \n",
    "    \n",
    "    # meshgrid()는 x축 정보(벡터), y축 정보(벡터)(a, b를 입력 받아\n",
    "    # 사각형 영역에 대한 정보를 반환한다.\n",
    "    # 실제 데이터를 전부 포함할 수 있는 컴팩트한 사각형의 범위를 잡는다.\n",
    "    aa, bb = np.meshgrid(hticks, vticks)# 확률 높였으니 decision bound도 찍어보\n",
    "    ab = np.c_[aa.ravel(), bb.ravel()]\n",
    "    #print(aa)\n",
    "    #print(bb.shape)\n",
    "    #print(ab)\n",
    "    \n",
    "    # help(np.meshgrid)\n",
    "    # 빗금치는 영역을 잡아줌 \n",
    "    # print(aa)\n",
    "    # ->사각형을 400개를 만들려면 그 정보도 400개 있어야 해서 그에 대한 정보가 행렬로 나타남\n",
    "    # print(bb.shape)\n",
    "    # print(aa.ravel)\n",
    "    # -> \n",
    "    # print(ab)\n",
    "    # ab = x, y 값 최대, 최소값이 확인 됨 사각형 영역 정보를 완벽하게 갖고 있음\n",
    "    # 원에 찍힌 데이터 값의 최소 최대를 보고 사각형 크기 알 수 있게 해주는것이 위의 코드\n",
    "    \n",
    "    \n",
    "    \n",
    "    # model.predict(ab)를 사용하여 아래쪽에서 contourf를 사용할 준비를 한다.\n",
    "    # c라는 정보는 결국 Contour에서 활용하는 등고선의 기준 높이로 활용된다.\n",
    "    c = model.predict(ab)\n",
    "    # print(c)\n",
    "    Z = c.reshape(aa.shape)\n",
    "    # 확률이 같은 애들을 이 범위내에 두겠다\n",
    "    # c는 아래의 contourf 사용하기 위해 있음\n",
    "    \n",
    "    \n",
    "    # contourf가 하는 일은?\n",
    "    # 빗금 = contourf = 등고선에 대한 정보를 줌\n",
    "    \n",
    "    # cmap, alpha는 **kwargs이 처리하게 되고\n",
    "    # aa, bb, Z는 *args이 처리하게 된다.\n",
    "    # cmap == ColorMap을 bwr을 택할 경우\n",
    "    # 아래쪽은 파랑색, 가운데는 흰색, 위쪽은 빨간색\n",
    "    # alpha값이란 것은 투명도를 의미한다.\n",
    "    # alpha값은 낮을수록 투명가 높으며\n",
    "    # 값이 높은 경우엔 색상이 진하게 칠해진다.\n",
    "    # plt.contourf를 통해서 등고선이 같은애들의 범주를 잡아줬다.\n",
    "    plt.contourf(aa, bb, Z, cmap = 'bwr', alpha = 0.2)\n",
    "    # plot_data를 통해서 실제 데이터들을 그래프상에 그렸다.\n",
    "    plot_data(plt, X, y)\n",
    "    return plt \n",
    "    # 빗금치는 영역을 잡아줌 \n",
    "    ## 가로축(x)세로축(y) (a, b) 받아서 사각형 영역에 정보를 반환 한다.\n",
    "    # print(aa)\n",
    "    # ->사각형을 400개를 만들려면 그 정보도 400개 있어야 해서 그에 대한 정보가 행렬로 나타남\n",
    "    # print(bb.shape)\n",
    "    # print(aa.ravel)\n",
    "    # -> \n",
    "    # print(ab)\n",
    "    # ab = x, y 값 최대, 최소값이 확인 됨 사각형 영역 정보를 완벽하게 갖고 있음\n",
    "    # 원에 찍힌 데이터 값의 최소 최대를 보고 사각형 크기 알 수 있게 해주는것이 위의 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# qoad = 4개 = 사각형 , *하나 있으면 가변인자 *arge \n",
    "# 등고선 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만든 모델 던지기 \n",
    "# decision boundary \n",
    "# 빗금이 대각선 = min, max 0.1\n",
    "#  0의 비율이 적고 1의 비율이 높으면 잘 만들어진 것\n",
    "\n",
    "plot_decision_bound(model, X, y)\n",
    "plt.title(\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 모델 만들고 확률값도 확인하고, 데이터도 찍어봣는데, 등고선을 만들어보니 같은 구간에서도 0과 1이 섞여있는 등 쓸 수 가 없음\n",
    "# -> 등고선을 좀 더 정확하게 만들 필요가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p133 모델 업그레이드\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(3, activation = 'relu', input_dim = 2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'binary_crossentropy')\n",
    "\n",
    "model.fit(X, y, batch_size = 5, epochs = 200, verbose = 1)\n",
    "# loss가 계속 줄어든 것을 볼 수 있음 30%-> (0.24)75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확률 높였으니 decision bound도 찍어보기\n",
    "plot_decision_bound(model, X, y)\n",
    "plt.title(\"Hidden Layer 3(tanh)\")\n",
    "\n",
    "# 육각형의 등고선 형태가 만들어짐\n",
    "# 구분선이 명확해짐 \n",
    "# 임계치 넘어가면 특정한 x값으로 간다?\n",
    "# 아쉬운점 확률을 더 올리자! -> 히든레이어 개수 늘리기 \n",
    "# 레이어 늘리니까 팔각형 모양의 등고선 형태가 만들어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 업그레이드 \n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(6, activation = 'relu', input_dim = 2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'binary_crossentropy')\n",
    "\n",
    "model.fit(X, y, batch_size = 5, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_bound(model, X, y)\n",
    "plt.title(\"Hidden Layer 3(tanh)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이어 500번 학습\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(6, activation = 'relu', input_dim = 2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'binary_crossentropy')\n",
    "\n",
    "model.fit(X, y, batch_size = 5, epochs = 500, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모양이 예쁜 육각형이 됨 = fit할 수 있는 한계 = 더 나아지지 않고 특정 값으로 수렴 = 93% = 100 중 7개는 틀린다 = 상용하기 어려움\n",
    "plot_decision_bound(model, X, y)\n",
    "plt.title(\"Hidden Layer 6(tanh)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 높이기 프로젝트 샘플개수 줄여보기 -> 실패 \n",
    "X, y = make_circles(\n",
    "    # 샘플 개수가 적더라도 정확한 데이터를 수집하는게 중요하다.\n",
    "    # 잘못된 정보를 수집하면 제대로된 A.I가 될 수 없다.\n",
    "    n_samples = 100, \n",
    "    factor = 0.6, \n",
    "    noise = 0.1, \n",
    "    random_state = 42\n",
    ")\n",
    "# 샘플의 개수가 적으니 인공 신경망의 특성상\n",
    "# 성능의 저하가 발생한 것을 확인할 수 있었다.\n",
    "\n",
    "# 성능을 어떻게 하면 더 높일 수 있을까?\n",
    "# 샘플을 줄이니까 성능이 낮아짐  loss = 0.2427\n",
    "# 샘플의 개수가 적더라도 정확한 데이터를 수집하는게 중요하다.\n",
    "# 웹크롤링은 잘못된 정보가 많음\n",
    "# 하드웨어 센서 데이터가 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(6, activation = 'relu', input_dim = 2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'binary_crossentropy')\n",
    "\n",
    "model.fit(X, y, batch_size = 5, epochs = 500, verbose = 1)\n",
    "# -> 레이어의 개수 늘려주는 것이 좋음 0.06 - > 94% \n",
    "# 진동 : loss 값이 올라갔다 내려갔다 하는 것\n",
    "# 모양이 좀 더 컴팩트 해짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_bound(model, X, y)\n",
    "plt.title(\"Hidden Layer 6(tanh)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능을 더ㅓㅓ 높이기 \n",
    "# 레이어 개수 디테일하게 늘리기  0.02 -> 98%\n",
    "# 진동을 무엇으로 잡을지 고민해보기\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(12, activation = 'relu', input_dim = 2))\n",
    "model.add(Dense(6, activation = 'tanh'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'binary_crossentropy')\n",
    "\n",
    "model.fit(X, y, batch_size = 5, epochs = 500, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_bound(model, X, y)\n",
    "plt.title(\"Hidden Layer 6(tanh)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조금 더 촘촘한 네트워크만들기 \n",
    "# 쥐어짜내보기\n",
    "# 맥스풀링쓰면 성능 좋아짐\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(500, activation = 'relu', input_dim = 2))\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(192, activation = 'relu'))\n",
    "model.add(Dense(256, activation = 'tanh'))\n",
    "model.add(Dense(128, activation = 'tanh'))\n",
    "model.add(Dense(96, activation = 'tanh'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(32, activation = 'tanh'))\n",
    "model.add(Dense(16, activation = 'tanh'))\n",
    "model.add(Dense(8, activation = 'tanh'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'binary_crossentropy')\n",
    "\n",
    "model.fit(X, y, batch_size = 5, epochs = 600, verbose = 1)\n",
    "# 600번 -> 99%\n",
    "# 이 이상하면 속도도 느려서 더 의미가 없음\n",
    "# 1000개 중 40개가 밖으로 나간 것\n",
    "# 상용은 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_bound(model, X, y)\n",
    "plt.title(\"Hidden Layer 6(tanh)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p135\n",
    "# 돈을 버냐 마냐는 1%로도 결정됨\n",
    "# 고가의 장비가 4개 고장 보단 1개 고장이 낫기 때문 \n",
    "# % 올라가면 정확도의 싸움 \n",
    "# 학습하려면 한달 걸린다 -> 기계를 이용을 못해서 기회비용\n",
    "# 네트워크 구성도 중요하지만 빨라야함\n",
    "\n",
    "# p138 p140\n",
    "# 과소적합 : 맞는거 틀린 거 다 섞여있음\n",
    "# 과적합 : 파랑색에는 노이즈 정보가 섞여 있는 것 = 노이즈까지 학습한 것 = 노이즈까지 데이터 처리 = 오동작 확률 높아짐 \n",
    "# p142 모델 수정 가능* 중요\n",
    "# 과소 적합 = 망의 크기 키워서 수정 / 과적합 = 망의 크기 줄이거나 더 많은 학습데이터 제공해서 과적합 줄임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p151  4장 교차 검증\n",
    "# 학습데이터가 앞쪽에 위치해 있으니 테스트세트를 학습시키기 위해 \n",
    "#테스트 위치를 바꿔가면서 테스트를 여러번 하자 \n",
    "# 미국의 군용기 중 정찰기 일반/대통령지시 -> 교차 검증해서 지시한게 맞는 정보인지 판정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Applied-Deep-Learning-with-Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls Applied-Deep-Learning-with-Keras/Lesson02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\n",
    "    \"./Applied-Deep-Learning-with-Keras/Lesson02/bank_data_feats.csv\",\n",
    "    index_col = 0\n",
    ")\n",
    "y = pd.read_csv(\n",
    "    \"./Applied-Deep-Learning-with-Keras/Lesson02/bank_data_target.csv\",\n",
    "    index_col = 0\n",
    ")\n",
    "\n",
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num of Dataset =\", data.shape[0])\n",
    "print(\"Num of Features =\", data.shape[1])\n",
    "print(y.shape)\n",
    "# 데이터 잘 들어갔는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 만들기 \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(16, input_dim = X.shape[1], activation = 'relu'))\n",
    "    model.add(Dense(8, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss = 'binary_crossentropy',\n",
    "        optimizer = 'adam',\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 검증 수행 준비 \n",
    "import numpy as np\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5 # 교차검증을 몇 번 할지\n",
    "epochs = 400\n",
    "batch_size = 10\n",
    "\n",
    "# 분류 작업을 할 때 사용하는 분류기 생성자\n",
    "classifier = KerasClassifier(\n",
    "    # 실질적으로 분류를 수행하는데 사용할 모델을 만드는 함수\n",
    "    build_fn = build_model, # *keras에서 제일 중요 \n",
    "    # 몇 회 반복을 할 것인가\n",
    "    epochs = epochs,\n",
    "    batch_size = batch_size,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(\n",
    "    n_splits = n_folds,\n",
    "    shuffle = True,\n",
    "    random_state = seed # 재현율 seed = 1 = 100 이여서 교차검증을  20씩 끊어서 5번 함 \n",
    "                        # 각각의 값 다를 수 있어도 재현은 되고 있기 때문에 데이터가 유지되는 한 \n",
    "                        # loss라는 데이터없이 검증 가능\n",
    "                        # 이 데이터를 학습하고 난 후에는 어떤 상황이여도 안정적인 데이터 가져옴\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(StratifiedKFold)\n",
    "# provides train/test indices(index복수형) to split data in train/test  sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우리가 가지고 있는 Train, Test 데이터에 대한 검증 생성자\n",
    "# Train, Test 총합 1000개 있다고 가정\n",
    "# 1. Train 0 ~ 799, Test 800 ~ 999\n",
    "# 2. Train 200 ~ 999, Test 0 ~ 199\n",
    "# 3. Train 0 ~199, 400 ~ 999, Test 200 ~ 399\n",
    "# .........\n",
    "kfold = StratifiedKFold(\n",
    "    # 전체 구간을 5 번으로 분할해서 검증하도록 만든다.\n",
    "    n_splits = n_folds,\n",
    "    shuffle = True,\n",
    "    random_state = seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 만든 분류기와 검증기를 전달해서 X, y값에 대한 교차 검증을 수행한다.\n",
    "results = cross_val_score(classifier, X, y, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 검증을 위해 처음부터 다시 테스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p159 classifier \n",
    "# indexes 배열의 ~\n",
    "# 학습을 오래하는 단점 + 오래해서 정밀도가 뛰어남(데이터의 안정성 높음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 88~90%의 정확성\n",
    "# 표준편차  0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(n_folds):\n",
    "    print(\"Accuracy at fold\", f + 1, \"=\", results[f])\n",
    "\n",
    "print(\"\")\n",
    "print(\"Final Cross Valid Test Accuracy:\", results.mean())\n",
    "print(\"Standard Deviation of Final Test Accuracy:\", results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러개 모델 사용해서 비교해보기\n",
    "# default parameter는 만약 인자가 없으면\n",
    "# 자동으로 해당 인자(parameter)를 지정된 녀석으로 주는 것\n",
    "def model_build1(activation = 'relu', optimizer = 'adam'):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(8, input_dim = X.shape[1], activation = activation))\n",
    "    model.add(Dense(8, activation = activation))\n",
    "    model.add(Dense(8, activation = activation))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss = 'binary_crossentropy',\n",
    "        optimizer = optimizer,\n",
    "        metrics = ['accuracy']\n",
    "    )optimizers\n",
    "    \n",
    "    return model\n",
    "\n",
    "def model_build2(activation = 'relu', optimizer = 'adam'):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(16, input_dim = X.shape[1], activation = activation))\n",
    "    model.add(Dense(8, activation = activation))\n",
    "    model.add(Dense(4, activation = activation))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss = 'binary_crossentropy',\n",
    "        optimizer = optimizer,\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "\n",
    "def model_build3(activation = 'relu', optimizer = 'adam'):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(8, input_dim = X.shape[1], activation = activation))\n",
    "    model.add(Dense(4, activation = activation))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss = 'binary_crossentropy',\n",
    "        optimizer = optimizer,\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    return model\n",
    "# 어떤 뉴럴네트워크 신경 네트워크망이 제일 좋은지 보는 것\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5 # 테스트 데이터가 1: 4니까 5로 잡음 \n",
    "batch_size = 5\n",
    "epochs = 200\n",
    "\n",
    "results = []\n",
    "\n",
    "models = [model_build1, model_build2, model_build3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(models)):\n",
    "    classifier = KerasClassifier(\n",
    "        build_fn = models[idx],\n",
    "        epochs = epochs,\n",
    "        batch_size = batch_size, \n",
    "        verbose = 1\n",
    "        \n",
    "    )\n",
    "    \n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits = n_folds,\n",
    "        shuffle = True,\n",
    "        random_state = seed\n",
    "    )\n",
    "    \n",
    "    result = cross_val_score(classifier, X, y, cv = kfold)\n",
    "    \n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 더 정밀하게 나오게 하려면 2~3000번 돌려야함\n",
    "for idx in range(len(models)):\n",
    "    print(\"Model\", idx + 1, \"TestAccuracy =\", results[idx].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameter (초 매개변수) 2:56:30\n",
    "# 교차 검증을 통해서 어떤 녀석을 활용하는 것이 가장 좋은지 판정할 수 있다.\n",
    "# 물론 난 컴퓨터를 사용할 수 없게 된다. \n",
    "optimizers = ['rmsprop', 'adam', 'sgd'] # 최적화 함수  \n",
    "activations = ['relu', 'tanh'] #활성화 함수\n",
    "#  optimizers는 피팅을 할 때(y=f(x)) 사용하는 알고리즘(정확도높이기, 오차 최소화, 로스를 줄이기) 같은 것의 정책 중 하나\n",
    "# 모든 Hyper Parameter  값을 덮어 씜def model_build1(activation = 'relu', optimizer = 'adam'):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(8, input_dim = X.shape[1], activation = activation))\n",
    "    model.add(Dense(8, activation = activation))\n",
    "    model.add(Dense(8, activation = activation))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss = 'binary_crossentropy',\n",
    "        optimizer = optimizer,\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "for opt in range(len(optimizers)):\n",
    "    for active in range(len(activations)):\n",
    "        optimizer = optimizers[opt]\n",
    "        activation = activations[active]\n",
    "        \n",
    "        classifier = KerasClassifier(\n",
    "            build_fn = model_build1,\n",
    "            epochs = 300,\n",
    "            batch_size = 5,\n",
    "            verbose = 1\n",
    "        )\n",
    "        \n",
    "        kfold = StratifiedKFold(\n",
    "            n_splits = n_folds,Epoch\n",
    "            shuffle = True,\n",
    "            random_state = seed\n",
    "        )\n",
    "        \n",
    "        result = cross_val_score(classifier, X, y, cv = kfold)\n",
    "        \n",
    "        results.append(result)1/300\n",
    "724/724 [==============================] - 1s 1ms/step - loss: 1.0007 - accuracy: 0.7937\n",
    "Epoch 2/300\n",
    "724/724 [==============================] - 1s 773us/step - loss: 0.6414 - accuracy: 0.8590\n",
    "Epoch 3/300\n",
    "724/724 [==============================] - 1s 808us/step - loss: 0.5730 - accuracy: 0.8689\n",
    "Epoch 4/300\n",
    "724/724 [==============================] - 1s 887us/step - loss: 0.4801 - accuracy: 0.8678\n",
    "Epoch 5/300\n",
    "724/724 [==============================] - 1s 816us/step - loss: 0.4436 - accuracy: 0.8700\n",
    "Epoch 6/300\n",
    "724/724 [==============================] - 1s 819us/step - loss: 0.4843 - accuracy: 0.8753\n",
    "Epoch 7/300\n",
    "724/724 [==============================] - 1s 904us/step - loss: 0.3560 - accuracy: 0.8836\n",
    "Epoch 8/300\n",
    "724/724 [==============================] - 0s 633us/step - loss: 0.3266 - accuracy: 0.8797\n",
    "Epoch 9/300\n",
    "724/724 [==============================] - 1s 825us/step - loss: 0.3156 - accuracy: 0.8803\n",
    "Epoch 10/300\n",
    "724/724 [==============================] - 1s 1ms/step - loss: 0.3134 - accuracy: 0.8811\n",
    "Epoch 11/300\n",
    "724/724 [==============================] - 1s 1ms/step - loss: 0.3106 - accuracy: 0.8850\n",
    "Epoch 12/300\n",
    "724/724 [==============================] - 1s 1ms/step - loss: 0.3121 - accuracy: 0.8841\n",
    "Epoch 13/300\n",
    "724/724 [==============================] - 1s 1ms/step - loss: 0.3040 - accuracy: 0.8866\n",
    "Epoch 14/300\n",
    "724/724 [==============================] - 1s 790us/step - loss: 0.3023 - accuracy: 0.8880\n",
    "Epoch 15/300\n",
    "724/724 [==============================] - 1s 936us/step - loss: 0.3033 - accuracy: 0.8880\n",
    "Epoch 16/300\n",
    "724/724 [==============================] - 1s 954us/step - loss: 0.3002 - accuracy: 0.8850\n",
    "Epoch 17/300\n",
    "724/724 [==============================] - 1s 947us/step - loss: 0.2969 - accuracy: 0.8930\n",
    "Epoch 18/300\n",
    "724/724 [==============================] - 1s 1ms/step - loss: 0.3051 - accuracy: 0.8874\n",
    "Epoch 19/300\n",
    "724/724 [==============================] - 1s 945us/step - loss: 0.3018 - accuracy: 0.8872\n",
    "Epoch 20/300\n",
    "724/724 [==============================] - 0s 650us/step - loss: 0.2949 - accuracy: 0.8883\n",
    "Epoch 21/300\n",
    "724/724 [==============================] - 1s 769us/step - loss: 0.3016 - accuracy: 0.8852\n",
    "Epoch 22/300\n",
    "724/724 [==============================] - 1s 873us/step - loss: 0.3015 - accuracy: 0.8830\n",
    "Epoch 23/300\n",
    "724/724 [==============================] - 1s 978us/step - loss: 0.3034 - accuracy: 0.8924\n",
    "Epoch 24/300\n",
    "724/724 [==============================] - 1s 1ms/step - loss: 0.3063 - accuracy: 0.8855\n",
    "Epoch 25/300\n",
    "724/724 [==============================] - 1s 952us/step - loss: 0.2909 - accuracy: 0.8880\n",
    "Epoch 26/300\n",
    "724/724 [==============================] - 1s 1ms/step - loss: 0.2923 - accuracy: 0.8924\n",
    "Epoch 27/300\n",
    "724/724 [==============================] - 1s 1ms/step - loss: 0.2855 - accuracy: 0.8899\n",
    "Epoch 28/300\n",
    "724/724 [==============================] - 1s 1ms/step - loss: 0.2868 - accuracy: 0.8874\n",
    "Epoch 29/300\n",
    "724/724 [==============================] - 0s 677us/step - loss: 0.2905 - accuracy: 0.8861\n",
    "Epoch 30/300\n",
    "724/724 [==============================] - 0s 668us/step - loss: 0.2882 - accuracy: 0.8916\n",
    "Epoch 31/300\n",
    "724/724 [==============================] - 0s 646us/step - loss: 0.2883 - accuracy: 0.8827\n",
    "Epoch 32/300\n",
    "724/724 [==============================] - 1s 785us/step - loss: 0.2959 - accuracy: 0.8891\n",
    "Epoch 33/300\n",
    "724/724 [==============================] - 1s 887us/step - loss: 0.2906 - accuracy: 0.8897\n",
    "Epoch 34/300\n",
    "724/724 [==============================] - 1s 865us/step - loss: 0.2904 - accuracy: 0.8858\n",
    "Epoch 35/300shuffle = True,\n",
    "            random_state = seed\n",
    "        )\n",
    "        \n",
    "        result = cross_val_score(classifier, X, y, cv = kfold)\n",
    "        \n",
    "        results.append(result)\n",
    "724/724 [==============================] - 1s 855us/step - loss: 0.2864 - accuracy: 0.8886\n",
    "Epoch 36/300\n",
    "724/724 [==============================] - 1s 996us/step - loss: 0.2914 - accuracy: 0.8827\n",
    "Epoch 37/300\n",
    "377/724 [==============>...............] - ETA: 0s - loss: 0.2659 - accuracy: 0.8950\n",
    "In [210]:\n",
    "￼\n",
    "c =\n",
    "            shuffle = True,\n",
    "            random_state = seed\n",
    "        )\n",
    "        \n",
    "        result = cross_val_score(classifier, X, y, cv = kfold)\n",
    "        \n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for opt in range(len(optimizers)):\n",
    "    for active in range(len(activations)):\n",
    "        print(\"activation =\", activations[active])\n",
    "        print(\"optimizer =\", optimizers[opt])\n",
    "        print(\"Test Accuracy =\", results[c].mean())\n",
    "        c += 1\n",
    "# 이 중 어떤게 가장 좋은지 알 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p162 \n",
    "# 교차 검증 cross_val_score\n",
    "#158\n",
    "# 편향도 : 얼마나 치우처저 있냐\n",
    "# 분산도 : 데이터가 평균값으로 부터 얼마나 떨어져 있냐\n",
    "# 원 문제 : k값이 작은 k-fold교차 검증쓰기  *상호간의 편향성이 높게 나오고 분산도가 낮아서 데이터가 잘 오밀조밀하게 있음\n",
    "# 편향성이 중요하지 않은 경우 LOO\n",
    "\n",
    "# p171  에러율이 높다 -> 새로운 것에 대한 학습할 준비가 되어있다는 것 \n",
    "# p172 Hyper Parmeter \n",
    "# p173 상용제품 만들려면 Hyper Parmeter, Loss, 도 고려하기 엑티베이션 뭐쓰고 에큐레시는 뭐쓰고 로스는 뭐쓸지 결과가 나와\n",
    "# 모델별로테스트 -> 1이 가장 좋네 -> 성능 높이기 위해 Hyper Parameter 사용 \n",
    "# *교차검증을 하는 이유 - 어떤 인공신경망 모델이 가장 좋은지\n",
    "# <모델을 쉽게 찾고 찾은 모델에 Hyper Parmeter로 입히는 것>\n",
    "# 시간과 돈,,,,\n",
    "# p174 실제 찍히는 y 값이 우리가 추정한 값과 다를 수 있음 +-오차를 더하면 서로 상쇄 ->0 -> 퍼펙트 ->말이 안되는 시스템 만들어짐\n",
    "# 제곱을 해서 오차를 없애자 -> 최소 제곱법\n",
    "# p184\n",
    "# 1. 모델 성능에 관한 교차 검증 추정치를 가지고 특정문제에 적합한 모델을 고르기\n",
    "# 2. 특정모"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
